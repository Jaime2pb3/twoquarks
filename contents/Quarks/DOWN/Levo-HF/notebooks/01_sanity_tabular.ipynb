import numpy as np
import matplotlib.pyplot as plt

from envs.corrupted_valley import CorruptedValleyEnv
from levo.levo_q_tabular import LevoQTabularAgent
from levo.levo_thinking_ensemble import LevoThinkingEnsembleAgent
from exp.run_corrupted_valley_tabular import (
    EpsGreedyQAgent,
    SoftmaxBoltzmannAgent,
)

def run_sanity_phase(
    phase_id: int,
    n_episodes: int,
    agents,
    base_seed: int = 2025,
):
    """
    Run a small number of episodes for each agent in a given phase
    and return simple statistics.

    Returns
    -------
    stats : dict
        stats[agent.name] = {
            "rewards": list of total rewards,
            "valley_visits": list of valley visit counts
        }
    """
    stats = {
        agent.name: {"rewards": [], "valley_visits": []}
        for agent in agents
    }

    for agent_idx, agent in enumerate(agents):
        for ep in range(n_episodes):
            seed = base_seed + phase_id * 1000 + agent_idx * 100 + ep
            env = CorruptedValleyEnv(seed=seed, phase=phase_id)
            rng = np.random.default_rng(seed)

            obs = env.reset()
            done = False
            total_reward = 0.0
            valley_visits = 0

            # For LevoThinking we optionally use noisy updates in phase 3.
            while not done:
                action = agent.select_action(obs, rng=rng)
                step = env.step(action)
                next_obs = step.obs
                reward = step.reward
                done = step.done
                info = step.info

                total_reward += reward
                if info.get("valley", False):
                    valley_visits += 1

                if isinstance(agent, LevoThinkingEnsembleAgent):
                    noisy_heads = None
                    noise_std = 0.0
                    if phase_id == 3:
                        # Use the same convention as in the main experiment:
                        # half of the heads receive noisy TD-updates.
                        k = max(1, agent.n_heads // 2)
                        noisy_heads = range(k)
                        noise_std = 0.1

                    agent.update(
                        obs,
                        action,
                        reward,
                        next_obs,
                        done,
                        noisy_heads=noisy_heads,
                        noise_std=noise_std,
                        rng=rng,
                    )
                else:
                    agent.update(obs, action, reward, next_obs, done)

                obs = next_obs

            stats[agent.name]["rewards"].append(total_reward)
            stats[agent.name]["valley_visits"].append(valley_visits)

    return stats


# Probe the environment to get sizes.
probe_env = CorruptedValleyEnv(seed=0, phase=1)
n_states = probe_env.n_states
n_actions = probe_env.n_actions

agents = [
    EpsGreedyQAgent(n_states, n_actions, epsilon=0.1, name="EpsGreedy"),
    SoftmaxBoltzmannAgent(n_states, n_actions, tau=0.5, name="Softmax"),
    LevoQTabularAgent(
        n_states,
        n_actions,
        A=0.5,
        omega=0.05,
        ent_weight=0.0,
        name="LevoQ",
    ),
    LevoThinkingEnsembleAgent(
        n_states,
        n_actions,
        n_heads=5,
        A=0.5,
        omega=0.05,
        lambda_var=0.5,
        name="LevoThinking",
    ),
]
agents



n_episodes_sanity = 30

all_phase_stats = {}

for phase_id in (1, 2, 3):
    # For each phase we recreate *fresh* agents to avoid cross-phase coupling here.
    agents_phase = [
        EpsGreedyQAgent(n_states, n_actions, epsilon=0.1, name="EpsGreedy"),
        SoftmaxBoltzmannAgent(n_states, n_actions, tau=0.5, name="Softmax"),
        LevoQTabularAgent(
            n_states,
            n_actions,
            A=0.5,
            omega=0.05,
            ent_weight=0.0,
            name="LevoQ",
        ),
        LevoThinkingEnsembleAgent(
            n_states,
            n_actions,
            n_heads=5,
            A=0.5,
            omega=0.05,
            lambda_var=0.5,
            name="LevoThinking",
        ),
    ]

    stats = run_sanity_phase(
        phase_id=phase_id,
        n_episodes=n_episodes_sanity,
        agents=agents_phase,
        base_seed=2025,
    )
    all_phase_stats[phase_id] = stats

all_phase_stats.keys()


def summarize_phase_stats(all_phase_stats):
    for phase_id, stats in sorted(all_phase_stats.items()):
        print(f"\n=== Phase {phase_id} ===")
        for agent_name, values in stats.items():
            rewards = np.array(values["rewards"], dtype=float)
            valleys = np.array(values["valley_visits"], dtype=float)
            print(
                f"{agent_name:12s} | "
                f"reward mean={rewards.mean():6.3f}, "
                f"std={rewards.std():6.3f} | "
                f"valley visits mean={valleys.mean():6.3f}"
            )

summarize_phase_stats(all_phase_stats)


def plot_phase_rewards(all_phase_stats, phase_id):
    plt.figure()
    for agent_name, values in all_phase_stats[phase_id].items():
        rewards = np.array(values["rewards"], dtype=float)
        plt.plot(rewards, marker="o", linestyle="-", label=agent_name)
    plt.xlabel("episode")
    plt.ylabel("total reward")
    plt.title(f"Corrupted Valley – Phase {phase_id}")
    plt.legend()
    plt.tight_layout()
    plt.show()


def plot_phase_valley_visits(all_phase_stats, phase_id):
    plt.figure()
    for agent_name, values in all_phase_stats[phase_id].items():
        valleys = np.array(values["valley_visits"], dtype=float)
        plt.plot(valleys, marker="o", linestyle="-", label=agent_name)
    plt.xlabel("episode")
    plt.ylabel("valley visits")
    plt.title(f"Corrupted Valley – Phase {phase_id}")
    plt.legend()
    plt.tight_layout()
    plt.show()


for phase_id in (1, 2, 3):
    plot_phase_rewards(all_phase_stats, phase_id)
    plot_phase_valley_visits(all_phase_stats, phase_id)
